from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import List, Dict, Any
import re
from datetime import datetime

# Padr√µes para an√°lise de t√≥picos
TOPIC_KEYWORDS = {
    'ansiedade': ['ansio', 'preocup', 'nervos', 'medo', 'p√¢nico', 'ang√∫stia', 'tens√£o', 'inquieta√ß√£o'],
    'depress√£o': ['triste', 'vazio', 'desesperan√ß', 'des√¢nimo', 'cansa√ßo', 'culpa', 'in√∫til', 'morte', 'suic√≠dio'],
    'estresse': ['estress', 'sobrecarr', 'press√£o', 'sobrecarregado', 'exausto', 'esgotado'],
    'relacionamentos': ['namorado', 'namorada', 'esposo', 'esposa', 'marido', 'mulher', 'pai', 'm√£e', 'filho', 'filha', 'amigo', 'amiga', 'colega', 'chefe'],
    'trabalho': ['trabalho', 'emprego', 'carreira', 'profissional', 'chefe', 'colegas', 'demiss√£o', 'promo√ß√£o'],
    'autoestima': ['feio', 'feia', 'inseguro', 'inseguran√ßa', 'confian√ßa', 'autoestima', 'auto-imagem', 'apar√™ncia'],
    'conquista': ['consegui', 'venci', 'superei', 'melhorei', 'evolu√≠', 'entendi', 'descobri', 'feliz', 'alegre', 'paz', 'tranquilo'],
}

def estimate_sentiment(text: str) -> float:
    """
    Estima um score de sentimento (-1.0 a 1.0) baseado em palavras-chave simples.
    Usado quando o score da IA n√£o est√° dispon√≠vel no banco.
    """
    if not text:
        return 0.0
        
    text = text.lower()
    score = 0.0
    
    # Pesos simples
    negatives = TOPIC_KEYWORDS['ansiedade'] + TOPIC_KEYWORDS['depress√£o'] + TOPIC_KEYWORDS['estresse']
    positives = TOPIC_KEYWORDS['conquista']
    
    # Contagem b√°sica
    neg_count = sum(1 for word in negatives if word in text)
    pos_count = sum(1 for word in positives if word in text)
    
    total = neg_count + pos_count
    if total == 0:
        return 0.0
        
    # Normaliza entre -1 e 1
    return (pos_count - neg_count) / max(total, 1)

def calculate_sentiment_trends(sessions: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analisa as tend√™ncias de sentimento ao longo das sess√µes.
    Retorna estat√≠sticas sobre o sentimento geral e sua evolu√ß√£o.
    """
    if not sessions:
        return {}
    
    sentiment_scores = []
    sentiment_by_date = defaultdict(list)
    
    for session in sessions:
        # Tenta pegar do banco, sen√£o calcula
        score = 0.0
        if session.get('analysis') and isinstance(session['analysis'], dict):
             sentiment = session['analysis'].get('sentiment', {})
             score = sentiment.get('score', 0)
        else:
             # Fallback: calcula na hora usando transcri√ß√£o ou resumo
             text = session.get('transcription') or session.get('summary') or ""
             score = estimate_sentiment(text)
            
        try:
            # Converte a string de data para objeto datetime
            created_at = datetime.fromisoformat(session['created_at'].replace('Z', '+00:00'))
            date_str = created_at.strftime('%Y-%m-%d')
            
            sentiment_scores.append(score)
            sentiment_by_date[date_str].append(score)
        except (KeyError, ValueError) as e:
            continue
    
    
    # Calcula estat√≠sticas de sentimento
    if not sentiment_scores:
        return {}
    
    avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
    
    # Calcula tend√™ncia (melhorando, piorando ou est√°vel)
    trend = 'est√°vel'
    if len(sentiment_scores) > 1:
        first_half = sentiment_scores[:len(sentiment_scores)//2]
        second_half = sentiment_scores[len(sentiment_scores)//2:]
        
        avg_first = sum(first_half) / len(first_half)
        avg_second = sum(second_half) / len(second_half)
        
        if avg_second > avg_first + 0.1:
            trend = 'melhorando'
        elif avg_second < avg_first - 0.1:
            trend = 'piorando'
    
    # Prepara dados para gr√°fico de evolu√ß√£o
    evolution_data = [
        {'date': date, 'avg_score': sum(scores)/len(scores)}
        for date, scores in sorted(sentiment_by_date.items())
    ]
    
    return {
        'average_score': round(avg_sentiment, 2),
        'trend': trend,
        'total_sessions_analyzed': len(sentiment_scores),
        'evolution': evolution_data
    }

def extract_common_topics(sessions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extrai t√≥picos comuns das transcri√ß√µes das sess√µes.
    Retorna uma lista de t√≥picos com suas frequ√™ncias.
    """
    if not sessions:
        return []
    
    topic_counter = Counter()
    
    for session in sessions:
        if not session.get('transcription'):
            continue
            
        text = session['transcription'].lower()
        
        # Conta ocorr√™ncias de cada t√≥pico
        for topic, keywords in TOPIC_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text:
                    topic_counter[topic] += 1
                    break  # Conta o t√≥pico apenas uma vez por sess√£o
    
    # Ordena por frequ√™ncia e retorna os 5 principais
    common_topics = [
        {'topic': topic, 'count': count}
        for topic, count in topic_counter.most_common(5)
    ]
    
    return common_topics

def calculate_session_frequency(sessions: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Calcula a frequ√™ncia das sess√µes ao longo do tempo.
    Retorna estat√≠sticas sobre a regularidade das sess√µes.
    """
    if not sessions:
        return {}
    
    # Extrai e ordena as datas das sess√µes
    try:
        session_dates = [
            datetime.fromisoformat(s['created_at'].replace('Z', '+00:00'))
            for s in sessions
            if s.get('created_at')
        ]
        session_dates.sort()
    except (KeyError, ValueError):
        return {}
    
    if not session_dates:
        return {}
    
    # Calcula intervalo m√©dio entre sess√µes
    intervals = []
    for i in range(1, len(session_dates)):
        delta = session_dates[i] - session_dates[i-1]
        intervals.append(delta.days)
    
    avg_interval = sum(intervals) / len(intervals) if intervals else 0
    
    # Conta sess√µes por dia da semana
    weekday_counts = defaultdict(int)
    for date in session_dates:
        weekday = date.strftime('%A')
        weekday_counts[weekday] += 1
    
    # Encontra o dia mais comum
    most_common_day = max(weekday_counts.items(), key=lambda x: x[1]) if weekday_counts else (None, 0)
    
    return {
        'total_sessions': len(session_dates),
        'first_session': session_dates[0].isoformat(),
        'last_session': session_dates[-1].isoformat(),
        'avg_days_between_sessions': round(avg_interval, 1),
        'sessions_per_week': round(7 / avg_interval, 1) if avg_interval > 0 else 0,
        'most_common_day': {
            'day': most_common_day[0],
            'count': most_common_day[1]
        } if most_common_day[0] else None,
        'sessions_by_weekday': dict(weekday_counts)
    }

def generate_clinical_record_content(session_data: Dict[str, Any], patient_data: Dict[str, Any], client: Any) -> Dict[str, Any]:
    """Generates structured clinical record content using OpenAI."""
    
    system_prompt = (
        "Voc√™ √© um supervisor cl√≠nico psicanal√≠tico rigoroso. "
        "Sua tarefa √© estruturar um Prontu√°rio Cl√≠nico formal com base nos dados da sess√£o."
    )
    
    user_prompt = f"""
    Dados do Paciente: {patient_data.get('name')}
    Dados da Sess√£o: {session_data.get('created_at')}
    Transcri√ß√£o/Resumo: {session_data.get('transcription') or session_data.get('summary')}
    Insights Anteriores: {session_data.get('insights')}
    
    Gere um JSON com os seguintes campos exatos para o prontu√°rio:
    1. queixa_principal: (foco da sess√£o)
    2. conteudo_sessao: (associa√ß√µes, relatos). Resuma em par√°grafos.
    3. observacoes_clinicas: (afetos, defesas, din√¢mica transferencial). Use terminologia t√©cnica (Freud/Lacan).
    4. intervencoes: (pontua√ß√µes, cortes, interpreta√ß√µes do analista).
    5. evolucao: (processos em curso).
    6. riscos: (suic√≠dio, autoles√£o, etc - seja conservador).
    7. plano_terapeutico: (pr√≥ximos passos).
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        response_format={"type": "json_object"}
    )
    
    import json
    return json.loads(response.choices[0].message.content)

def generate_clinical_record_pdf(record_data: Dict[str, Any], patient_data: Dict[str, Any], session_date: str) -> bytes:
    """Generates the PDF file for the clinical record."""
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib import colors
    from io import BytesIO
    
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    elements = []
    
    # Styles
    title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=16, spaceAfter=20, alignment=1)
    header_style = ParagraphStyle('Header', parent=styles['Normal'], fontSize=10, textColor=colors.gray)
    section_style = ParagraphStyle('Section', parent=styles['Heading2'], fontSize=12, spaceBefore=15, spaceAfter=10, textColor=colors.darkblue)
    text_style = ParagraphStyle('Text', parent=styles['Normal'], fontSize=11, leading=14)
    
    # Header Info
    elements.append(Paragraph("Prontu√°rio Cl√≠nico ‚Äì Sess√£o Psicanal√≠tica", title_style))
    elements.append(Spacer(1, 10))
    
    # Format Patient Data for the section
    patient_info = (
        f"<b>Nome:</b> {patient_data.get('name') or 'N/A'}\n"
        f"<b>Email:</b> {patient_data.get('email') or 'N/A'}\n"
        f"<b>Telefone:</b> {patient_data.get('phone') or 'N/A'}\n"
        f"<b>Data da sess√£o:</b> {session_date}"
    )

    # Sections
    sections = [
        ("üë§ Dados do Paciente", patient_info),
        ("üß† 1. Queixa principal / Motivo da sess√£o", record_data.get('queixa_principal', '-')),
        ("üó£Ô∏è 2. Conte√∫do da sess√£o", record_data.get('conteudo_sessao', '-')),
        ("üîç 3. Observa√ß√µes cl√≠nicas", record_data.get('observacoes_clinicas', '-')),
        ("üîÑ 4. Interven√ß√µes do analista", record_data.get('intervencoes', '-')),
        ("üìà 5. Evolu√ß√£o / Processos em curso", record_data.get('evolucao', '-')),
        ("‚ö†Ô∏è 6. Riscos / Observa√ß√µes importantes", record_data.get('riscos', '-')),
        ("üìù 7. Plano terap√™utico / Encaminhamentos", record_data.get('plano_terapeutico', '-'))
    ]
    
    for title, content in sections:
        elements.append(Paragraph(title, section_style))
        elements.append(Paragraph(content.replace('\n', '<br/>'), text_style))
        elements.append(Spacer(1, 10))
        
    # Signature
    elements.append(Spacer(1, 30))
    elements.append(Paragraph("_______________________________", text_style))
    elements.append(Paragraph("Assinatura do Profissional", text_style))
    
    doc.build(elements)
    buffer.seek(0)
    return buffer.getvalue()